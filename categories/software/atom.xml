<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: software | Uptonian Thoughts]]></title>
  <link href="http://blog.thomasupton.com/categories/software/atom.xml" rel="self"/>
  <link href="http://blog.thomasupton.com/"/>
  <updated>2015-10-29T15:04:45-05:00</updated>
  <id>http://blog.thomasupton.com/</id>
  <author>
    <name><![CDATA[Thomas Upton]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Installing the Latest ZSH on Travis CI]]></title>
    <link href="http://blog.thomasupton.com/2015/08/installing-and-using-the-latest-zsh-on-travis-ci"/>
    <updated>2015-08-20T20:25:07-05:00</updated>
    <id>http://blog.thomasupton.com/2015/08/installing-and-using-the-latest-zsh-on-travis-ci</id>
    <content type="html"><![CDATA[<p>I recently thought it might be a good idea to start using <a href="https://travis-ci.org/">Travis CI</a> to run builds of my personal repositories on a regular basis. A lot of my repositories are pet projects, but that doesn’t mean that I don’t depend on them on a daily basis.</p>

<p>That couldn’t be more true of <a href="https://github.com/tupton/dotfiles">my dotfiles</a>. My <a href="https://github.com/tupton/dotfiles/blob/a5597784778bca973188300b8fff40f9688b2cf5/zsh/zshrc"><code>zshrc</code></a> and my <a href="https://github.com/tupton/dotfiles/blob/a5597784778bca973188300b8fff40f9688b2cf5/vim/vimrc"><code>vimrc</code></a> get exercised tens if not hundreds of times per day. Sometimes I’ll make a change to test out something new, verify that it doesn’t blow up, commit it, and move on. That’s probably not the best way to do things, but I figure that I’ll never start using the new hotness if I don’t jump in and start using it right away. Usually this works out well and I’ve simply added a new tool to my repertoire, but it can potentially break my environment in subtle ways. Continuous integration can help with that: if I commit a breaking change, I can get an email when the “build” breaks. I’ll immediately know which commit broke something without having to resort to <code>git blame</code> or something similar.</p>

<p>Travis CI offers a fantastic free service, but I haven’t really had a chance to use it yet.<sup id="fnref:travis-vs-jenkins"><a href="#fn:travis-vs-jenkins" class="footnote">1</a></sup> I figured that setting up CI for my small dotfiles repository would be a great way to learn a tool that many open source projects use today.</p>

<p>There was one huge hurdle: I use <code>zsh</code>, and most of my dotfile setup scripts are written in <code>zsh</code>, but the <a href="http://docs.travis-ci.com/user/ci-environment/">Travis environment</a> only comes with the <code>bash</code> shell installed.<sup id="fnref:default-shell"><a href="#fn:default-shell" class="footnote">2</a></sup></p>

<p>Some <a href="https://github.com/zsh-users/antigen/blob/7860ce7aecdbed8fd8ff75472ac59c52c2ac9a7e/.travis.yml#L32">existing open</a> <a href="https://github.com/Tarrasch/zsh-bd/blob/e56411daa979996297295515422b618e7419f8fb/.travis.yml#L5">source projects</a> use Travis with <code>zsh</code>, but they all use the legacy environment that still allows <code>sudo</code>, not the <a href="http://docs.travis-ci.com/user/migrating-from-legacy/">newer container-based environment</a>. The <a href="http://docs.travis-ci.com/user/apt/">apt addon</a> can help install packages in containers, but the latest version of <code>zsh</code> on Ubuntu 12.04 is 4.3.17. <code>zsh</code> 5 is a requirement for most modern usages, so that’s a non-starter. I thought that someone would have come across this already and solved it, and maybe they have, but I couldn’t easily find a solution.</p>

<p>We need to build and install <code>zsh</code>, and we need to do it without <code>sudo</code>. <code>build-essential</code> is already available on the Travis CI virtual machines, and we could use the aforementioned apt addon if it wasn’t.</p>

<p>After much <a href="https://travis-ci.org/tupton/dotfiles/builds">trial and error</a>, I finally got a Travis config that makes sure a recent version of <code>zsh</code> is set up before running the build. I chose to do this in the <code>before_install</code> step because that <a href="http://docs.travis-ci.com/user/customizing-the-build/#The-Build-Lifecycle">seems to be where additional dependencies should be installed</a>, but I suppose it could be done anywhere in the build lifecycle before <code>script</code> runs the actual tests.</p>

<p>The full Travis config follows, but the <code>before_install</code> step is what really matters:</p>

<p><code>yaml
language: sh
addons:
  apt:
    packages:
    - build-essential
before_install:
- export LOCAL="$(mktemp --directory --tmpdir=${TMPDIR:/tmp} local.bin.XXXXXX)"
- curl -L http://downloads.sourceforge.net/zsh/zsh-5.0.7.tar.gz | tar zx
- cd zsh-5.0.7
- ./configure --prefix=$LOCAL
- make
- make install
- cd -
- export PATH="$LOCAL/bin:$PATH"
script: make test
</code></p>

<p>First, we make a temporary directory to install <code>zsh</code> to. Remember, no <code>sudo</code> means no access to <code>/usr/bin/local</code>, so we need to choose a safe location to install.</p>

<p>Next, we download the latest version of <code>zsh</code>. If you want to use a different mirror or download an archive with a different compression, you just need to change this line to handle that and the rest should work. If you change the version, make sure to update the following line that changes directories to the archive you just decompressed.</p>

<p>Then we build <code>zsh</code>: configure with the prefix set to the directory we created earlier, then <code>make</code> it and <code>make install</code> it to the prefixed directory.</p>

<p>Finally, we <code>cd</code> back to the directory we were in – these build lifecycle steps are run in series so we need to hop back to the directory we were in before building <code>zsh</code> – and, more importantly, we add the temporary directory to the beginning of our path so that <code>zsh</code> can be found.</p>

<p>These <code>before_install</code> steps could probably be extracted into a script, but I wanted to go with the simplest Travis config with the least overhead to get up and running with <code>zsh</code>. Now, when the test script runs, <code>zsh</code> is available and we can check our scripts for errors!</p>

<p>I look forward to exploring more of what is possible with Travis. On my horizon: using <a href="https://github.com/Kuniwak/vint"><code>vint</code></a> to lint my vimrc and writing tests for the majority of my private repositories that don’t currently have any verification.</p>

<div class="footnotes">
  <ol>
    <li id="fn:travis-vs-jenkins">
      <p>We use Jenkins at work, which is a blessing and a curse. Mostly the latter, but the sheer number of plugins available coupled with the fact that I work with some awesome people who know Jenkins better than I ever will makes it ok. <a href="#fnref:travis-vs-jenkins" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:default-shell">
      <p>Really, it comes with whatever shell is default for the operating system that Travis VMs use. Since <a href="http://docs.travis-ci.com/user/ci-environment/#Virtualization-environments">they run Ubuntu 12.04</a>, that means that <code>bash</code> is available but <code>zsh</code> is not. It seems like Travis didn’t set out to explicitly support shell-based projects, but because their machines are (mostly) Linux, that comes for “free” if you know how to configure things. <a href="#fnref:default-shell" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Reading My News]]></title>
    <link href="http://blog.thomasupton.com/2012/07/reading-my-news"/>
    <updated>2012-07-12T18:12:22-05:00</updated>
    <id>http://blog.thomasupton.com/2012/07/reading-my-news</id>
    <content type="html"><![CDATA[<p>I’ve used Google Reader for a long time, but I’ve never been completely satisfied with using it to
read and keep up with RSS feeds. Apps like <a href="http://flipboard.com/">Flipboard</a> on the iPad provide a better
reading experience for traditionally “newsy” outlets – I enjoy flipping through the feeds from <em>The
New Yorker</em>, <em>The Economist</em>, and <em>The Atlantic</em> – but following feeds where every item is of
personal interest to me doesn’t make much sense in that context, and it’s iOS-only. I had used
<a href="http://netnewswireapp.com/">NetNewsWire</a> a few times in the past, but I never stuck with it for some reason. It’s
a great app, but I would constantly get distracted by that big red badge with a huge number of
unread items in it.</p>

<p>I realized that my problem wasn’t really the apps I was using. What really made reading my feeds
imperfect – or even tedious – was the number of feeds I had and <em>how</em> I was reading them. I decided
to revisit NetNewsWire and check out an app on iOS that I had heard great things about.</p>

<h2 id="prune">Prune</h2>

<p>The first key to revamping my news reading was pruning my subscriptions. I had way too many
high-traffic feeds, and I wasn’t even reading 1% of some of them. I would go through all my feeds
and folders and mark everything as read every few days<sup id="fnref:too-long"><a href="#fn:too-long" class="footnote">1</a></sup> just to keep up and feel like I
wasn’t overwhelmed.</p>

<p>I got rid of feeds from sites like <a href="http://www.lamebook.com/">Lamebook</a>, which is hilarious, but I don’t need to
read every single item, and <a href="http://www.absolutepunk.net/">Absolute Punk</a>, which is a great source for music news, but I only
want to read a very small portion of those stories. I get my fix from these sites by visiting them
every few days, not by trying to forge through a murky river of hundreds of RSS items that I don’t
want to read.</p>

<p>I now have 26 feeds in 8 categories,<sup id="fnref:cross-link"><a href="#fn:cross-link" class="footnote">2</a></sup> down from twice that before pruning. This is
manageable. 50+ high-traffic feeds are not. I can read the items from these feeds quickly, and I
can finally read “all items” without becoming overwhelmed.</p>

<h2 id="netnewswire-revisited-again">NetNewsWire, revisited (again)</h2>

<p>I mentioned that I had used NetNewsWire before, but it never stuck. A couple of weeks ago, I saw
<a href="http://collindonnell.com/2012/06/29/my-netnewswire-window/">this NetNewsWire setup</a> and knew I had to try it. <code>⌘-⇧-R</code> and <code>⌘-/</code> are now my favorite
keyboard shortcuts. Refresh, and then scroll through my unread river of items. I sort
chronologically so I read posts “in order,” but I don’t think it actually matters much at all.
Since I have a low number of feeds, it usually only takes a few minutes to travel through these
unread items. Any links to things I want to check out in more depth later get a quick <code>^-P</code> to send
to Instapaper.</p>

<h2 id="reeder-on-mobile">Reeder on mobile</h2>

<p>I was recently on vacation without my MacBook, but I had my iPad and still wanted to keep up with my
news and feeds. There are plenty of other times that I’m without my computer but have a chance to
catch up on my reading. I figured (or hoped, really) that I could make the experience of reading
news on my iPhone and iPad just as great as it is with NetNewsWire at my desk.</p>

<p>I had heard great things about <a href="http://reederapp.com/">Reeder</a> on iOS, but I was skeptical that it could work for
me. It turns out I can get nearly the same river of news setup as NetNewsWire in Reeder. Unread
items can be sorted in chronological order, and moving to the next item is just a matter of swiping
up.</p>

<p>The end result is that I have a streamlined way to catch up on news that’s important to me as
quickly as possible, no matter where I am. I spend less time fiddling with news items I don’t really
care about, less time out of my day being distracted by the latest hot article,<sup id="fnref:distract"><a href="#fn:distract" class="footnote">3</a></sup> and more
time doing what I want and need to do.</p>

<div class="footnotes">
  <ol>
    <li id="fn:too-long">
      <p>I did this ritual for far too long before I realized it needed to end. Old habits die hard. <a href="#fnref:too-long" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:cross-link">
      <p>I’ve noticed that a lot of sites and blogs I read will “cross-post” each other’s items. This sounds like it might be annoying to have to read about the same things in multiple places, but usually one of two things happens: either the cross-posting contains a bit of insightful back-and-forth on a topic, or multiple people link to a great article elsewhere that I know I need to check out. I get to follow great discussions and the cream of the hot topic crop rises to the top of my news readers. Win-win for me. <a href="#fnref:cross-link" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:distract">
      <p>If only I could figure out how to stop checking <a href="http://stellar.io/">Stellar</a> so much. <a href="#fnref:distract" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My Essential Tools]]></title>
    <link href="http://blog.thomasupton.com/2012/01/my-essential-tools"/>
    <updated>2012-01-05T16:16:30-06:00</updated>
    <id>http://blog.thomasupton.com/2012/01/my-essential-tools</id>
    <content type="html"><![CDATA[<p>In light of some <a href="http://carpeaqua.com/2011/12/19/my-ultimate-developer-and-power-users-tool-list-for-mac-os-x-2011-edition-/">recent</a> <a href="http://collindonnell.com/blog/2012/1/4/essential-tools-2011.html">excellent</a> posts about tools that smart people use, here are my essential tools that I used in 2011.</p>

<h2 id="hardware">Hardware</h2>

<p>I use a 15” MacBook Pro i5 with 8 GB of RAM. It’s quick and does everything I need it to. It’s not <em>too</em> bulky, but it’s certainly bigger than my older 13” MacBook. I keep toying with the idea of a MacBook Air, but I can’t justify the cost and I don’t want to use two machines.</p>

<p>I connect to an Apple LED Cinema Display when I’m at my standing desk, and I use a <a href="http://www.amazon.com/gp/product/B002MMY4WY/ref=as_li_ss_tl?ie=UTF8&tag;=thomupto-20&linkCode;=as2&camp;=1789&creative;=390957&creativeASIN;=B002MMY4WY">Logitech wireless keyboard</a> and an Apple Magic Trackpad.</p>

<p>I do <a href="http://www.thomasupton.com/blog/2011/12/local-backups-are-great/">daily, local backups</a> to a smallish volume on a 1 TB hard drive. The rest of the drive holds my music, photos, and other media.</p>

<h2 id="software">Software</h2>

<p>I do all of my work (both professionally and on this site) on VMs in “the cloud” that I <code>ssh</code> to with <a href="http://www.iterm2.com/#/section/home">iTerm 2</a>. I love that it can copy-on-select and the customizable colors are more robust than in other terminal apps. I used the built in Terminal.app for a long time, but the latest iTerm 2 is stable and excellent.</p>

<p>I also use <a href="http://ditchnet.org/httpclient/">HTTP Client</a> to test our API, as well as both Firefox and Chrome.</p>

<p>When I write code, I usually use <a href="http://www.vim.org/"><code>vim</code></a>, but I’ve been testing out the recent alpha builds of <a href="http://blog.macromates.com/2011/textmate-2-0-alpha/">TextMate 2</a>.</p>

<p>When I write for this website or for my own personal notes, I’ve started using <a href="http://bywordapp.com/">Byword</a> to write and preview Markdown. Its fullscreen and “paragraph focus” modes are nice touches. I’ve heard good things about <a href="http://markedapp.com/">Marked</a>, which allows Markdown previews from any app, but I haven’t used it yet.</p>

<p>I’m not a huge calendar user, but I do keep track of <a href="http://www.last.fm/user/TUpton/events">shows I attend</a> and personal events on Google Calendar. I interact with my calendars with <a href="http://flexibits.com/fantastical">Fantastical</a>. Its natural language event input is pretty great and lets me add events really quickly.</p>

<p>I work on and use a browser-based email client at work, but I also like to use <a href="http://sparrowmailapp.com/">Sparrow</a>. The minimal interface stays out of the way, but all my mail is available quickly. Shortcuts for reply and reply all make it easy to respond to threads. A nice little touch: Sparrow automatically picked up the fact that I had an IMAP folder called Archive in my work email and started using it when I press Delete to archive messages.</p>

<p>I use <a href="http://www.alfredapp.com/">Alfred</a> all day every day. My usage statistics say I average 13.6 uses per day, but if you didn’t count weekends, holidays, or days that I don’t actually use my computer, I bet it’d be a lot higher. I <em>love</em> the clipboard management.</p>

<p>I occasionally use <a href="http://getcloudapp.com/">Cloud</a> to quickly upload screenshots, but I don’t use it for much else.</p>

<p>I use <a href="https://www.dropbox.com/">Dropbox</a> to manage files, share some music with friends, and back up certain documents. I also store my (encrypted) <a href="https://agilebits.com/onepassword">1Password</a> data on Dropbox so that I can access my passwords from anywhere.</p>

<p><a href="http://mizage.com/#macdivvy">Divvy</a> and <a href="http://cordlessdog.com/stay/">Stay</a> are two window management tools that I use all the time. When I disconnect from my display, Stay puts my windows back to where I want them. It doesn’t quite work with Chrome, but everything else works well. Divvy lets me resize windows on a custom-sized grid. You can even define shortcuts – I use “c” for a centered window and “6” for a window taking up 60% of the right side of the screen.</p>

<p>I recently started using <a href="http://www.evernote.com/">Evernote</a>, but I haven’t gotten into it just yet. I’ll have more to write about that when learn how to use it and actually start using it more. I do use <a href="http://www.evernote.com/about/download/clearly.php">Evernote’s Clearly</a> browser extension to read articles on line.</p>

<p>For my musical pleasure throughout the day, I still use iTunes a lot of the time. However, <a href="http://www.rdio.com/">Rdio</a> (with <a href="http://www.rogueamoeba.com/airfoil/">Airfoil</a>) is usually how I listen to music these days. Airfoil makes it easy to listen to music in my living room via my Apple TV.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Automated Backups with Tarsnap]]></title>
    <link href="http://blog.thomasupton.com/2010/12/automated-backups-with-tarsnap"/>
    <updated>2010-12-12T20:14:08-06:00</updated>
    <id>http://blog.thomasupton.com/2010/12/automated-backups-with-tarsnap</id>
    <content type="html"><![CDATA[<p>I remember <a href="http://www.daemonology.net/blog/2006-09-13-encrypted-backup.html">reading</a> <a href="http://www.daemonology.net/blog/2008-11-10-tarsnap-public-beta.html">about</a> <a href="http://www.tarsnap.com/">Tarsnap</a> a couple of years ago, back when it was only an idea. I wasn’t too convinced about using a service that was in beta to back up my data, but I recently rediscovered that it had graduated to a full-blown product and signed up immediately.</p>

<p>Tarsnap is an encrypted backup tool based on archives. I’m not going to go into any details about the implementation, but you can read about the <a href="http://www.tarsnap.com/crypto.html">cryptography</a>, <a href="http://www.tarsnap.com/security.html">the security</a>, or anything else about the <a href="http://www.tarsnap.com/design.html">overall design</a> of the tool on the <a href="http://www.tarsnap.com/">Tarsnap site</a>. Basically, it creates archives (hence the “tar” part of the name), encrypts them, and stores them on <a href="http://aws.amazon.com/s3/">Amazon S3</a>. The “snap” part of the name refers to the idea that backups are done in “snapshots,” which means that backups are incremental and duplicate data can be shared between archives.</p>

<p>After you sign up for a Tarsnap account, put at least $5 (via Paypal) into your account, and <a href="http://www.tarsnap.com/man-tarsnap-keygen.1.html">generate a key</a>, you can begin backing up your data. You can read more about <a href="http://www.tarsnap.com/gettingstarted.html">getting started</a> and <a href="http://www.tarsnap.com/usage.html">using <code>tarsnap</code> in general</a>, but I really want to talk about automated backups with Tarsnap.</p>

<h2 id="a-simple-wrapper">A Simple Wrapper</h2>

<p>I found <a href="http://jonathanstreet.com/blog/setting-up-backups-with-tarsnap">a blog post by Jonathan Street</a> that detailed his automated backups, and that served as inspiration for my system. I wrote a little bash script to wrap <code>tarsnap</code> for my purposes:</p>

<p><code>bash
    #! /bin/bash
    echo `date +%F\ %T`: Beginning back up of $2
    /usr/local/bin/tarsnap -c -f $1-`date +%F` $2
    echo `date +%F\ %T`: Completed back up of $2
</code></p>

<p>Calling <code>tarsnap-backup.sh  </code> tells tarsnap to create an archive  of the specified directory with the given name and the current date. I was in business.</p>

<h3 id="generating-a-new-key">Generating a new key</h3>

<p>An aside: Jonathan Street’s blog post mentioned creating a new key that only had permission to read and write archives. I initially did the same thing, but for reasons I’ll get into later, I wanted the ability to delete backups, too. Generating a new key was extremely easy:</p>

<p><code>bash
    $ tarsnap-keymgmt --outkeyfile /root/tarsnap-rw.key -r -w /root/tarsnap.key
</code></p>

<p>This creates a new key in <code>/root/</code> called <code>tarsnap-rw.key</code> that only has read and write permission.</p>

<h2 id="automation">Automation</h2>

<h3 id="newsyslog"><code>newsyslog</code></h3>

<p>The simple wrapper script above was great, but if I was going to automate it, I needed those <code>echo</code> statements to go to a more permanent log file. If I was going to do daily backups of directories, I needed some sort of log management. After searching around a bit, it became clear that <code>newsyslog</code> was the way to go on OS X. Looking at the file in <code>/etc/newsyslog.conf</code> was enough to give me the basic file structure, but the <a href="http://www.openbsd.org/cgi-bin/man.cgi?query=newsyslog&sektion;=8">man pages</a> go into a lot of detail.</p>

<p>I made a configuration called <code>user.conf</code> in <code>/etc/newsyslog.d/</code> and put my tarsnap logs inside. I decided to use a distinct log for each automated backup I do, as opposed to a single tarsnap log. I still haven’t decided if this is the right way to go, but I do like being able to quickly see the result of the last backup. My <code>user.conf</code> looks like the following.</p>

<pre><code>/var/log/tarsnap-backup-code.log                        640     5       1000    *       Z
/var/log/tarsnap-backup-documents.log                   640     5       1000    *       Z
</code></pre>

<p>This configuration tells <code>newsyslog</code> to gzip, roll to a new log once the current log exceeds 1MB in size, and keep at most five old logs.</p>

<h3 id="cron"><code>cron</code></h3>

<p>With log rotation in place, I could create a cron job.</p>

<pre><code>0 4 * * * /usr/local/bin/tarsnap-backup code ~/code &gt; /var/log/tarsnap-backup-code.log
</code></pre>

<p>This crontab schedules backups for my <code>code</code> directory at 4am daily and my <code>Documents</code> directory at 5am daily. I used <code>sudo crontabe -e</code> to create this because both <code>tarsnap</code> and my log file’s permissions require root privileges. This would have sufficed, but there was a nagging thought in the back of my head: I <a href="http://www.thomasupton.com/blog/2009/09/i-love-weather/">knew</a> that <code>launchd</code> is used in place of <code>cron</code> in OS X, and I thought this would give me a good opportunity to dive into even more options that <code>launchd</code> has to offer.</p>

<h3 id="launchd"><code>launchd</code></h3>

<p>Since I wanted these backups to run whenever possible, I decided to put my <code>launchd</code> backup configurations in <code>/Library/LaunchDameons</code> instead of <code>/Library/LaunchAgents</code>. LaunchDaemons are able to run without a logged-in user; this is exactly what I wanted. The <code>launchd</code> configuration for my <code>code</code> backup looks like the following:</p>

<p><code>html
    &lt;?xml version="1.0" encoding="UTF-8"?&gt;
    &lt;!DOCTYPE plist PUBLIC "-//Apple Computer//DTD PLIST 1.0//EN"
    "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;
    &lt;plist version="1.0"&gt;
    &lt;dict&gt;
        &lt;key&gt;Label&lt;/key&gt;
        &lt;string&gt;com.thomasupton.backup-daily-code&lt;/string&gt;
        &lt;key&gt;ProgramArguments&lt;/key&gt;
        &lt;array&gt;
            &lt;string&gt;/usr/local/bin/tarsnap-backup&lt;/string&gt;
            &lt;string&gt;code&lt;/string&gt;
            &lt;string&gt;/Users/thomas/code&lt;/string&gt;
        &lt;/array&gt;
        &lt;key&gt;GroupName&lt;/key&gt;
        &lt;string&gt;wheel&lt;/string&gt;
        &lt;key&gt;UserName&lt;/key&gt;
        &lt;string&gt;root&lt;/string&gt;
        &lt;key&gt;Nice&lt;/key&gt;
        &lt;integer&gt;1&lt;/integer&gt;
        &lt;key&gt;StandardErrorPath&lt;/key&gt;
        &lt;string&gt;/var/log/tarsnap-backup-code.log&lt;/string&gt;
        &lt;key&gt;StandardOutPath&lt;/key&gt;
        &lt;string&gt;/var/log/tarsnap-backup-code.log&lt;/string&gt;
        &lt;key&gt;StartCalendarInterval&lt;/key&gt;
        &lt;dict&gt;
            &lt;key&gt;Hour&lt;/key&gt;
            &lt;integer&gt;5&lt;/integer&gt;
            &lt;key&gt;Minute&lt;/key&gt;
            &lt;integer&gt;0&lt;/integer&gt;
        &lt;/dict&gt;
    &lt;/dict&gt;
    &lt;/plist&gt;
</code></p>

<p>The <code>ProgramArguments</code> section is exactly how I called the backup script from <code>cron</code>. The <code>UserName</code> and <code>GroupName</code> keys are important: they tell <code>launchd</code> to run the backup script as root, which, as I mentioned before, is necessary for using <code>tarsnap</code> and for appending to the log file. The <code>StandardErrorPath</code> and <code>StandardOutPath</code> keys tell <code>launchd</code> to redirect output to the proper log file. The <code>StartCalendarInterval</code> tells <code>launchd</code> to run this script at 5am daily.</p>

<p>After registering the configuration via <code>launchctl load /Library/LaunchDaemons/com.thomasupton.backup-daily-documents.plist</code>, my automated backup system was in place.</p>

<h2 id="backup-management">Backup Management</h2>

<p>Since Tarsnap backs up data with the notion of “snapshots” and keeps track of blocks of data (and not archive data), keeping multiple archives of the same data doesn’t make much sense. However, running a daily backup by creating a new archive would mean that many archives would build up fast. I decided that keeping at most three previous backups of the same data would suffice. I wanted to automate this, too. This is the reason I decided not to use a read-write-only key.</p>

<p>I added the following lines to my <code>tarsnap-backup.sh</code> script.</p>

<p><code>bash
    # Remove the backup from three days previous, if there is one
    echo `date +%F\ %T`: Removing backup of $2 from `date -v-3d +%F`
    /usr/local/bin/tarsnap -d -f $1-`date -v-3d +%F`
    echo `date +%F\ %T`: Completed removing backup of $2 from `date -v-3d +%F`
</code></p>

<p>The key to this is the date in the archive name passed to <code>tarsnap -d</code>. <code>date -v</code> lets you add a value to the date output, so <code>-v-3d</code> outputs the date from three days previous. Now, every scheduled backup attempts to delete the archive from three days ago in addition to creating a backup for the current day. Of course, if a backup is missed, this can lead to an accumulation of old archives. This is where the log files come in handy: I can just inspect the logs every couple of days to see what successfully ran and manually prune the archive list if necessary.</p>

<h3 id="large-backups">Large Backups</h3>

<p>I said “if a backup is missed,” but I didn’t mention why that might occur. The answer becomes apparent when you start talking about backing up large amounts of data. My <code>~/Documents</code> folder was over 12GB, and with my terrible upload speeds, that would mean that it would take a long, long time to upload everything. Even though I was able to prune the contents of <code>~/Documents</code> down to 6.5GB, I still needed more than an hour to back it up. <code>tarsnap</code> doesn’t perform more than one archive transaction at once, so if the <code>documents</code> archive was still running when the <code>code</code> archive process began, tarsnap would cancel the latter and continue with the former, hence a backup is missed. This is also another reason that I decided to keep separate log files for each backup job. The log lines for an in-progress job aren’t interspersed with a failed attempt to start another backup job.</p>

<p>The <code>documents</code> backup was still too large to have been done by the morning, and I didn’t really want to sacrifice my network connection just for the sake of a backup. Fortunately, <code>tarsnap</code> supports archive truncation. According to the <a href="http://www.tarsnap.com/man-tarsnap.1.html">man pages</a>, <code>tarsnap</code> responds to the <code>SIGQUIT</code> interrupt by truncating the archive and appending “<code>.part</code>” to the archive name. When my large backup job was still running, all I had to do was send the <code>SIGQUIT</code> signal with <code>kill -3</code> (alternatively, you could send <code>^Q</code> if you use <code>tarsnap</code> from a console and not from a scheduled job) and <code>tarsnap</code> would effectively “pause” the backup. The next time that same data is archived, <code>tarsnap</code> will recognize it and only upload new data. This works even with a different archive name, thanks to snapshots and block data.</p>

<h2 id="restoring-backups">Restoring Backups</h2>

<p>Tarsnap is a great service, but truly for those who know what they are doing. It took me far longer than I would like to admit to come up with a process for all of this, but it was worth it. Of course, creating backups is only one part of a complete system. The other, more important part, is restoration. Since <code>tarsnap</code> is built on <code>tar</code> and <code>libarchive</code>, this is incredibly simple. <code>tarsnap -x</code> extracts archives, and <code>tarsnap -r</code> writes a tar stream to <code>stdout</code>, which can be used to create a local tar.</p>

<p>If you like the idea of easy, encrypted backups, tarsnap is a great service. It’s cheap, secure, and reliable, plus it’s fun and easy to use if you’re comfortable with UNIX-style archiving tools.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pastebin From The Command-line]]></title>
    <link href="http://blog.thomasupton.com/2010/12/pastebin-from-the-commandline"/>
    <updated>2010-12-11T14:42:56-06:00</updated>
    <id>http://blog.thomasupton.com/2010/12/pastebin-from-the-commandline</id>
    <content type="html"><![CDATA[<p><a href="http://pastebin.com/">Pastebin.com</a> is a utility for sharing snippets of text with anyone. The service is simple: go to <a href="http://pastebin.com/">pastebin.com</a>, paste your text, click submit, and share the link. It’s useful for sharing time-saving snippets with you team, or for an impromptu, informal code review of changes that for one reason or another haven’t been committed yet (e.g. a design decision for which the author wants early feedback.)</p>

<blockquote>
  <p><em>10:56:55 AM</em> <strong>Mike Bulman</strong>: im gonna try to find one, but if it doesn’t exist im gonna write:  a service/app for osx that will post whatevers on the clipboard to pastebin and give you a url</p>
</blockquote>

<p>A couple of days ago, my friend <a href="http://twitter.com/#!/mikebulman">Mike</a> suggested that he wanted a utility that would make it easy to post to pastebin without having to break your workflow and go to the site. I thought “that sounds fun,” and went to work that evening.</p>

<p>Pastebin has a <a href="http://pastebin.com/api.php">simple RPC API</a> for posting content, and it’s perfect for <code>curl</code>. The very first version of the pastebin script was this simple <code>curl</code> script.</p>

<p><code>bash
    #! /usr/bin/env bash
    curl -s -X POST -d "paste_code=$1" "http://pastebin.com/api_public.php" | pbcopy
</code></p>

<p><code>paste_code</code> is the POST parameter that the pastebin API expects to contain pasted content, so we just POST that to the public API page. The output of a successful pastebin API call is the URL for the paste, so we pipe that to OS X’s clipboard for easy pasting. Right from the beginning, this is clearly an OS X-specific script, but I don’t think it would be that hard to interact with the Linux system clipboard via <code>xclip</code>.</p>

<p>Making this work for text from <code>stdin</code> instead of as an argument was easy, too.</p>

<p><code>bash
    #! /usr/bin/env bash
    to_paste=`cat /dev/stdin`
    curl -s -X POST -d "paste_code=$to_paste" "http://pastebin.com/api_public.php" | pbcopy
</code></p>

<p>Both Mike and I recently started using <a href="http://jumpcut.sourceforge.net/">Jumpcut</a>, a minimal clipboard manager for OS X, so I had the idea of copying the actual text that was posted to pastebin before copying the URL so both would be readily available via Jumpcut. I tried adding <code>echo "$to_paste" | pbcopy</code> before the <code>curl</code> call, but it didn’t always work. I didn’t actually find any documentation on it, but it seems that <code>pbcopy</code> does some sort of buffering so that too much text isn’t copied in quick succession. Adding a very hacky <code>sleep</code> call fixed it, so the resulting script became the following.</p>

<p><code>bash
    #! /usr/bin/env bash
    to_paste=`cat /dev/stdin`
    echo "$to_paste" | pbcopy
    sleep 1
    curl -s -X POST -d "paste_code=$1" "http://pastebin.com/api_public.php" | pbcopy
</code></p>

<p>Having a commandline script is all well and good, but it’s on about the same usability level as using pastebin.com: instead of switching to a browser, you switch to a terminal, but you still have to paste content and get away from you original context. This is where OS X Services come into play.</p>

<p>The OS X Service menu is often neglected, but it’s very useful. There are some neat built-in services, like looking a word up in Dictionary or composing a new email with the selection. With tools like  <a href="http://www.macosxautomation.com/automator/">Automator</a> or <a href="http://wafflesoftware.net/thisservice/">ThisService</a>, creating your own service is easy. I created an Automator workflow that assumed the script was symbolically linked to <code>/usr/local/bin/pastebin</code> and called the script. You can easily add a keyboard shortcut to a Service in the System Preferences Keyboard Shortcuts preference pane.</p>

<p>I cleaned up the script by adding a few command line options using the <code>getopts</code> <code>bash</code> built-in. This was pretty useful and easy to use. I’m not a very proficient <code>bash</code> scripter, but I was easily able to add what I needed, including making the ability to copy the text optional and allowing a file to be used in place of <code>stdin</code>. <a href="http://ginatrapani.org/">Gina Trapani</a>’s excellent <a href="https://github.com/ginatrapani/todo.txt-cli">todo.txt</a> script was helpful in figuring out the correct syntax.</p>

<p><code>bash
    while getopts ":cf:h" Option
    do
        case $Option in
            c )
                PASTEBIN_COPY=1
                ;;
            f )
                PASTEBIN_FILE=$OPTARG
                ;;
            h )
                usage
                ;;
        esac
    done
</code></p>

<p>I wrapped the script and the Automator workflow and <a href="https://github.com/tupton/pastebin-cl/">added it to github</a>. You can <a href="https://github.com/tupton/pastebin-cl/blob/8ff3cdda9e0027c41416b285f2822781a0ba4b5e/pastebin.sh">view the original bash script</a> in its latest form if you’re interested.</p>

<p>All this was well and good, but a couple of things bothered me. I didn’t like that <code>sleep</code> call, and I knew that the pastebin API offered a few options that I wasn’t allowing users of this script to take advantage of. So I did what any normal developer would do: I rewrote the script in python. The <a href="https://github.com/tupton/pastebin-cl/blob/d462c57542e98f23c83dc6388e1e5ebbafe04c94/pastebin.py">original version of the script</a> was just a straight “port” of the <code>bash</code> script, but I had plans for more.</p>

<p>I have experience with <a href="https://github.com/tupton/python-yahoo-weather">simple python scripts</a>, but I decided I should try my luck using classes in order to wrap the pastebin API. It was really easy. The beginning of the class looked like the following.</p>

<p>&#8220;` python
    class Pastebin(object):
        “&#8221;”A wrapper for the pastebin API”””</p>

<pre><code>    pastebin_api = "http://pastebin.com/api_public.php"

    def __init__(self, paste_code, paste_name=None, paste_email=None, paste_subdomain=None,
            paste_private=False, paste_expire_date=PASTEBIN_EXPIRE_NEVER, paste_format=None):

        self.set_paste_code(paste_code)
        self.set_paste_name(paste_name)
        self.set_paste_email(paste_email)
        self.set_paste_subdomain(paste_subdomain)
        self.set_paste_private(paste_private)
        self.set_paste_expire_date(paste_expire_date)
        self.set_paste_format(paste_format) ```
</code></pre>

<p>Then all I had to do was use the class.</p>

<p><code>python
    pastebin = Pastebin(paste_code=lines, paste_name=opts.paste_name, paste_email=opts.paste_email,
                paste_subdomain=opts.paste_subdomain, paste_private=opts.paste_private,
                paste_expire_date=opts.paste_expire_date, paste_format=opts.paste_format)
    response = pastebin.paste()
    return response
</code></p>

<p>I have no idea if getters and setters are very “pythonic,” but they make sense to me, even if I’m only using them internally for this script. I used a pretty interesting trick to build the POST data string. I put the necessary data into a dictionary, but I needed to build a proper parameter string.</p>

<p><code>python
    return "&amp;".join([k + "=" + str(v) for (k, v) in params.iteritems()])
</code></p>

<p>I love the syntax used for “inline” for-loops here. The extra <code>str()</code> call was used just in case a parameter (like expiration date) was accidentally interpreted as a number.</p>

<p>I updated the <a href="https://github.com/tupton/pastebin-cl/blob/master/README.md">README</a> to reflect the new options. Thankfully, only the symbolic link to <code>/usr/local/bin/pastebin</code> had to be updated in order to keep the workflow working. Using the pastebin script couldn’t be easier:</p>

<ol>
  <li><a href="https://github.com/tupton/pastebin-cl/archives/master">Download the script source</a>, extract it, and put it somewhere that makes sense, like <code>~/scripts</code>.</li>
  <li><code>ln -s ~/scripts/pastebin-cl/pastebin.py /usr/local/bin/pastebin</code></li>
  <li>Open the workflow in <code>automator/Paste to pastebin.com.workflow</code> and save it as a service, which should just be as easy as ⌘-S.</li>
  <li>Open System Preferences &gt; Keyboard, then Keyboard Shortcuts, then Services. Make sure that the “Paste to pastebin.com” service is checked. Optionally, you can give it a keyboard shortcut.</li>
  <li>Highlight some text in any OS X application and choose “Paste to pastebin.com” from the application menu’s “Services” submenu or use your keyboard shortcut. Now the pastebin URL is on you clipboard, ready to be pasted into a chat room or in a browser.</li>
</ol>

<p>Hopefully this script will be useful to developers all over. If you have any ideas about making this more portable (i.e. for use on Linux or Windows), let me know in the <a href="#respond">comments</a>.</p>

]]></content>
  </entry>
  
</feed>
